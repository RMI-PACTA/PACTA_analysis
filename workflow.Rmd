---
title: "PACTA_analysis workflow"
author: "Clare"
date: "08/02/2021"
output: html_document
---

## Aim

The aim of this document is to outline the workflow for running a PACTA project. 

## PACTA_analysis Repo

The PACTA_analysis repo contains the primary PACTA functions required to run a portfolio alignment assessment for investors. The current repository is built in a way that the functions work for both an online application - ie for the P2020 projects and platform; as well as the original application which is running a project or generating results offline.

Whether online or offline, running an analysis has three components

1. Portfolio Cleaning: Clean the input portfolio and merge in financial data, to categorise each holding and identify whether it's equity (EQ) or corporate bonds (CB)
2. Run Analysis: Merge in ald + scenarios, and group results at company, portfolio and regional level
3. Results: Present the results in a clear output format

Both the online and offline scripts can be used to generate reports offline. The difference is that the offline set of scripts is set up to allow the generation of results for multiple portfolios and investors in one run, whereas online is focussed on quickly generating a report for one portfolio at once. While all steps maintain the grouping by investor and portfolio, to allow for this, it hasn't been optimised for running multiple portflios as once. The online tool however has been designed for the interactive reports, whereas the offline scripts have primarily been used to generate the static pdf results.  


### Portfolio Cleaning

This occurs in web_tool_script_1.R (online) or 2_project_input_analysis.R (offline). 

Both start with reading in the necessary files. This includes some file cleaning, that should be shifting to the data_preprataion repository.  

## Difference between online and offline

There are two sets of scripts that call the functions required for both offline or online functionality. 

Online: The "web_tool_script" set from 1 to 3 runs through the components of the analysis
Offline: The 1,2,3,4 scripts run similarly, however have an initialisation script that should be run before each online in order to set up project pathways and naming. This allows for added flexibility as you may online want to be focussing on one of the components of the analysis. Ie you've already generated results and just want to create output files. 


# Running a project


## Offline 
This steps through the functions required to run a project using the original scripts. The aim of this script is to define project paths and set parameters used in the following scripts. 

### Set up parameters and paths
```{r 1_portfolio_check_initialisation, echo = FALSE}

devtools::load_all()
use_r_packages()

## Project Initialisation

working_location <- paste0(getwd(), "/")

source("0_portfolio_test.R")
source("0_graphing_functions.R")
source("0_reporting_functions.R")
source("0_portfolio_input_check_functions.R")
source("0_global_functions.R")
source("0_sda_approach.R")

project_name <- "TestProject"
twodii_internal <- FALSE
# TRUE or FALSE: TRUE means that the code is running on a 2dii laptop with dropbox connection

#####################################################################
### ONLY FOR EXTERNAL PROJECTS (twodii_internal <- FALSE):
# Variables must exist for internal projects
project_location_ext <- "C:/Users/clare/Desktop/ExternalTest"
data_location_ext <- "C:/Users/clare/Desktop/PACTA/pacta-data/2019Q4"
#####################################################################

create_project_folder(project_name, twodii_internal, project_location_ext)

set_project_paths(project_name, twodii_internal, project_location_ext)

copy_files(project_name)

options(r2dii_config = fs::path(par_file_path, "AnalysisParameters.yml"))


# parameters
project_code <- "GENERAL"

set_global_parameters(fs::path(par_file_path, "AnalysisParameters.yml"))

set_project_parameters(file.path(working_location, "parameter_files",paste0("ProjectParameters_", project_code, ".yml")))

analysis_inputs_path <- set_analysis_inputs_path(twodii_internal, data_location_ext, dataprep_timestamp)

```

TO DO: 

- Improve the sourcing of files. Setting the internal flag to false to allow for defining this is one solution here. 

- Synchronise the parameter files with the online parameter files



### Portfolio input analysis

Aims:

- Reads in necessary data files and cleans them 

To Run: 

- You need a portfolio to be placed in the folder ```{r} fs::path(project_location_ext, project_name, "20_Raw_Inputs")```. There are sample files found in this repository in the folder "sample_files"

Note:

- Fund file optional. This adds additional holdings to the portfolio (adds in the details of the companies owned within a fund). If the file for the current time stamp is there this should be read in. Often this file is project specific as the file size can be very large. 

- this is currently reading in the "cleaned" files found in the pacta-data repo. This workflow needs to be cleaned up so that these "cleaned" files can be created for any project.  

```{r 2_project_input_analysis, echo = FALSE}

####################
#### DATA FILES ####
####################

file_location <- file.path(analysis_inputs_path, "cleaned_files")

currencies <- fst::read_fst(file.path(file_location, "currencies.fst"))

read_fst_or_return_null <- function(fst_file) {
  if (!file.exists(fst_file)) {
    return(NULL)
  }
  
  fst::read_fst(fst_file)
}

fund_data_path <- file.path(file_location, "fund_data.fst")

fund_data <- read_fst_or_return_null(fund_data_path)

fin_data <- fst::read_fst(file.path(file_location, "fin_data.fst"))

comp_fin_data <- fst::read_fst(file.path(file_location, "comp_fin_data.fst"))

debt_fin_data <- fst::read_fst(file.path(file_location, "debt_fin_data.fst"))

if (inc_emission_factors) {
  average_sector_intensity <- fst::read_fst(file.path(file_location, "average_sector_intensity.fst"))
  
  company_emissions <- fst::read_fst(file.path(file_location, "company_emissions.fst"))
}

####################
#### PORTFOLIOS ####
####################
portfolio_raw <- read_raw_portfolio_file(project_name)

# Portfolios and investors in the project
portfolio_raw %>% select(Investor.Name, Portfolio.Name) %>% distinct() %>% pull(Portfolio.Name, Investor.Name)

portfolio <- process_raw_portfolio(
  portfolio_raw,
  fin_data,
  fund_data,
  currencies,
  grouping_variables
)

portfolio <- add_revenue_split(has_revenue, portfolio, revenue_data)

portfolio <- create_ald_flag(portfolio, comp_fin_data, debt_fin_data)

eq_portfolio <- create_portfolio_subset(
  portfolio,
  "Equity"
)

cb_portfolio <- create_portfolio_subset(
  portfolio,
  "Bonds"
)

portfolio_total <- add_portfolio_flags(portfolio)

portfolio_overview <- portfolio_summary(portfolio_total)

identify_missing_data(portfolio_total)

audit_file <- create_audit_file(portfolio_total)

create_audit_chart(audit_file, proc_input_path)

emissions_totals <- calculate_portfolio_emissions(
  inc_emission_factors,
  audit_file,
  fin_data,
  comp_fin_data,
  average_sector_intensity,
  company_emissions
)

################
#### SAVING ####
################
if (length(file_format_list) == 0) {
  stop("Saving results: No file formats defined")
}

if ("csv" %in% file_format_list) {
  if (data_check(portfolio_total)) {
    write_csv(portfolio_total, paste0(proc_input_path, "/", project_name, "_total_portfolio.csv"))
  }
  if (data_check(eq_portfolio)) {
    write_csv(eq_portfolio, paste0(proc_input_path, "/", project_name, "_equity_portfolio.csv"))
  }
  if (data_check(cb_portfolio)) {
    write_csv(cb_portfolio, paste0(proc_input_path, "/", project_name, "_bonds_portfolio.csv"))
  }
  if (data_check(portfolio_overview)) {
    write_csv(portfolio_overview, paste0(proc_input_path, "/", project_name, "_overview_portfolio.csv"))
  }
  if (data_check(audit_file)) {
    write_csv(audit_file, paste0(proc_input_path, "/", project_name, "_audit_file.csv"))
  }
  if (data_check(emissions_totals)) {
    write_csv(emissions_totals, paste0(proc_input_path, "/", project_name, "_emissions.csv"))
  }
}

if ("rds" %in% file_format_list | "rda" %in% file_format_list) {
  if (data_check(portfolio_total)) {
    write_rds(portfolio_total, paste0(proc_input_path, "/", project_name, "_total_portfolio.rda"))
  }
  if (data_check(eq_portfolio)) {
    write_rds(eq_portfolio, paste0(proc_input_path, "/", project_name, "_equity_portfolio.rda"))
  }
  if (data_check(cb_portfolio)) {
    write_rds(cb_portfolio, paste0(proc_input_path, "/", project_name, "_bonds_portfolio.rda"))
  }
  if (data_check(portfolio_overview)) {
    write_rds(portfolio_overview, paste0(proc_input_path, "/", project_name, "_overview_portfolio.rda"))
  }
  if (data_check(audit_file)) {
    write_rds(audit_file, paste0(proc_input_path, "/", project_name, "_audit_file.rda"))
  }
  if (data_check(emissions_totals)) {
    write_rds(emissions_totals, paste0(proc_input_path, "/", project_name, "_emissions.rda"))
  }
}

```

TO DO:

- move cleaning to data preparation


### Run Analysis

This step merges in the ald_scen file to the specific portfolio, and aggregates at the different levels of granularity required for the results - portfolio level and company level. 




```{r echo=FALSE}

##################
##### EQUITY #####
##################

equity_input_file <- paste0(proc_input_path, "/", project_name, "_equity_portfolio.rda")

if (file.exists(equity_input_file)) {
  port_raw_all_eq <- read_rds(equity_input_file) %>%
    mutate(id = as.character(id))
  
  ald_scen_eq <- get_ald_scen("Equity")
  
  ald_raw_eq <- get_ald_raw("Equity")
  
  list_investors_eq <- unique(port_raw_all_eq$investor_name)
  
  for (e in 1:length(list_investors_eq)) {
    map_eq <- NA
    company_all_eq <- NA
    port_all_eq <- NA
    
    investor_name_select <- list_investors_eq[e]
    print(paste0(e, ": ", investor_name_select))
    
    port_raw_eq <- port_raw_all_eq %>% filter(investor_name == investor_name_select)
    
    port_eq <- calculate_weights(port_raw_eq, "Equity", grouping_variables)
    
    port_eq <- merge_in_ald(port_eq, ald_scen_eq)
    
    # Portfolio weight methodology
    port_pw_eq <- port_weight_allocation(port_eq)
    
    company_pw_eq <- aggregate_company(port_pw_eq)
    
    port_pw_eq <- aggregate_portfolio(company_pw_eq)
    
    # Ownership weight methodology
    port_own_eq <- ownership_allocation(port_eq)
    
    company_own_eq <- aggregate_company(port_own_eq)
    
    port_own_eq <- aggregate_portfolio(company_own_eq)
    
    # Create combined outputs
    company_all_eq <- bind_rows(company_pw_eq, company_own_eq)
    
    port_all_eq <- bind_rows(port_pw_eq, port_own_eq)
    
    if (has_map) {
      map_eq <- merge_in_geography(company_all_eq, ald_raw_eq)
      
      map_eq <- aggregate_map_data(map_eq)
    }
    
    # Technology Share Calculation
    port_all_eq <- calculate_technology_share(port_all_eq)
    
    company_all_eq <- calculate_technology_share(company_all_eq)
    
    # Scenario alignment calculations
    port_all_eq <- calculate_scenario_alignment(port_all_eq)
    
    company_all_eq <- calculate_scenario_alignment(company_all_eq)
    
    investor_results_path <- paste0(results_path, "/", investor_name_select, "/")
    if (!dir.exists(investor_results_path)) {
      dir.create(investor_results_path)
    }
    
    if (data_check(company_all_eq)) {
      write_rds(company_all_eq, paste0(investor_results_path, "Equity_results_company.rda"))
    }
    if (data_check(port_all_eq)) {
      write_rds(port_all_eq, paste0(investor_results_path, "Equity_results_portfolio.rda"))
    }
    if (has_map) {
      if (data_check(map_eq)) {
        write_rds(map_eq, paste0(investor_results_path, "Equity_results_map.rda"))
      }
    }
  }
}

#################
##### BONDS #####
#################

bonds_inputs_file <- paste0(proc_input_path, "/", project_name, "_bonds_portfolio.rda")

if (file.exists(bonds_inputs_file)) {
  port_raw_all_cb <- read_rds(bonds_inputs_file) %>%
    mutate(id = as.character(id))
  
  ald_scen_cb <- get_ald_scen("Bonds")
  
  ald_raw_cb <- get_ald_raw("Bonds")
  
  list_investors_cb <- unique(port_raw_all_cb$investor_name)
  
  for (b in 1:length(list_investors_cb)) {
    map_cb <- NA
    company_all_cb <- NA
    port_all_cb <- NA
    
    investor_name_select <- list_investors_cb[b]
    
    print(paste0(b, ": ", investor_name_select))
    
    port_raw_cb <- port_raw_all_cb %>% filter(investor_name == investor_name_select)
    
    port_cb <- calculate_weights(port_raw_cb, "Bonds", grouping_variables)
    
    port_cb <- merge_in_ald(port_cb, ald_scen_cb)
    
    # Portfolio weight methodology
    port_pw_cb <- port_weight_allocation(port_cb)
    
    company_pw_cb <- aggregate_company(port_pw_cb)
    
    port_pw_cb <- aggregate_portfolio(company_pw_cb)
    
    # Create combined outputs
    company_all_cb <- company_pw_cb
    
    port_all_cb <- port_pw_cb
    
    if (has_map) {
      if (data_check(company_all_cb)) {
        map_cb <- merge_in_geography(
          portfolio = company_all_cb,
          ald_raw = ald_raw_cb
        )
        
        map_cb <- aggregate_map_data(map_cb)
      }
    }
    
    # Technology Share Calculation
    if (nrow(port_all_cb) > 0) {
      port_all_cb <- calculate_technology_share(port_all_cb)
    }
    
    if (nrow(company_all_cb) > 0) {
      company_all_cb <- calculate_technology_share(company_all_cb)
    }
    
    # Scenario alignment calculations
    port_all_cb <- calculate_scenario_alignment(port_all_cb)
    
    company_all_cb <- calculate_scenario_alignment(company_all_cb)
    
    investor_results_path <- paste0(results_path, "/", investor_name_select, "/")
    if (!dir.exists(investor_results_path)) {
      dir.create(investor_results_path)
    }
    
    if (data_check(company_all_cb)) {
      write_rds(company_all_cb, paste0(investor_results_path, "Bonds_results_company.rda"))
    }
    if (data_check(port_all_cb)) {
      write_rds(port_all_cb, paste0(investor_results_path, "Bonds_results_portfolio.rda"))
    }
    if (has_map) {
      if (data_check(map_cb)) {
        write_rds(map_cb, paste0(investor_results_path, "Bonds_results_map.rda"))
      }
    }
  }
}


```

There are options as to where to proceed from here. From this point there are options:
/item Run the stress testing code
/item Print static graphics and the pdf report (older code)
/item Print the interactive report (html) and executive summary (pdf) 

This is where there is a different in workflow between the online and offline case.
The offline workflow directs a user to the pdf code that we've been using recently. There should be little stopping a user from printing a html report, however the script to do this may need to be created. 


#### SDA Approach

The SDA approach is a methodology that is used for "Other" Sectors that do not have clear technology roadmaps, such as Steel, Cement, and Aviation but do have emission factor models. 

This is just a test really to understand how this code works as we may want to incorporate and not lose this work that was done by Vincent. 

```{r}

msci_world <- read_rds(file.path(data_location_ext, "Indices_equity_portfolio.rda")) %>% 
  filter(portfolio_name == "iShares MSCI World ETF")

port_all_eq_sda <- sda_portfolio_target(market = msci_world,
                          portfolio = port_all_eq,
                          scenario = "ETP2017_B2DS",
                          geography = "Global",
                          ald_sector = c("Cement","Steel", "Aviation"),
                          start_year = start_year,
                          target_year = 2025)



```

## Results

To come. 
